# Naestro providers: multi-node DGX Spark (local-first) + cloud spillover

inference:
  local:
    # DGX A
    - id: llama70b_judge_dgx_a
      runtime: tensorrt_llm
      model: llama-3.1-70b-instruct-fp8
      endpoint: http://dgx-a:8001
      max_batch: 4
      kv_cache: fp8
      roles: [judge, proposer]

    - id: deepseek32b_dgx_a
      runtime: vllm
      model: deepseek-v3.2-32b-instruct
      endpoint: http://dgx-a:8002
      max_batch: 8
      roles: [proposer, synthesizer]

    - id: qwen32b_awq_dgx_a
      runtime: vllm
      model: qwen-3-32b-instruct-awq
      endpoint: http://dgx-a:8003
      max_batch: 12
      roles: [critic, code]

    # DGX B
    - id: llama70b_judge_dgx_b
      runtime: tensorrt_llm
      model: llama-3.1-70b-instruct-fp8
      endpoint: http://dgx-b:8001
      max_batch: 4
      kv_cache: fp8
      roles: [judge, proposer]

    - id: deepseek32b_dgx_b
      runtime: vllm
      model: deepseek-v3.2-32b-instruct
      endpoint: http://dgx-b:8002
      max_batch: 8
      roles: [proposer, synthesizer]

    - id: qwen32b_awq_dgx_b
      runtime: vllm
      model: qwen-3-32b-instruct-awq
      endpoint: http://dgx-b:8003
      max_batch: 12
      roles: [critic, code]

  cloud:
    - id: openai_gpt4x
      provider: openai
      model: gpt-4.1
      auth_env: OPENAI_API_KEY
      roles: [overflow, long_context]

    - id: anthropic_claude37
      provider: anthropic
      model: claude-3-7-opus
      auth_env: ANTHROPIC_API_KEY
      roles: [judge, safety_backup]

    - id: google_gemini25
      provider: google
      model: gemini-2.5-pro
      auth_env: GOOGLE_API_KEY
      roles: [long_context]

routing:
  policy: local_first_with_cloud_spill
  defaults:
    judge: llama70b_judge_dgx_a
    proposer: deepseek32b_dgx_a
    critic: qwen32b_awq_dgx_a
    synthesizer: deepseek32b_dgx_a
  fallbacks:
    judge: [llama70b_judge_dgx_b, anthropic_claude37, openai_gpt4x]
    proposer: [deepseek32b_dgx_b, openai_gpt4x]
    critic: [qwen32b_awq_dgx_b, openai_gpt4x]
    synthesizer: [deepseek32b_dgx_b, google_gemini25]
  limits:
    max_concurrency: 16
    max_tokens_per_run: 120000
    long_context_threshold: 200000

retrieval:
  vector_store:
    kind: qdrant
    url: http://127.0.0.1:6333
    collection: naestro_docs
  embeddings:
    local: bge-large
    cloud_fallback: text-embedding-3-large

planner:
  engine: langgraph   # or dspy / none
  timeout_ms: 60000

evaluation:
  rag: ragas
  general: deepeval

safety:
  primary: nemo_guardrails
  pii_filters: [email, phone, credit_card]

